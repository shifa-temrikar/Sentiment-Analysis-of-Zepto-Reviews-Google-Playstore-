# -*- coding: utf-8 -*-
"""Sentiment Analysis of Zepto Reviews (Google Playstore)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U74DMkY25hAuALBEf6XwkcVj5V-Uyc4A

ðŸ” Project Overview

This project analyzes real-time customer reviews of the Zepto app collected from the Google Playstore.
The goal is to understand customer sentiment, highlight key issues, and derive insights to improve customer experience.

The pipeline includes:

- Data Collection (web scraping)

- Text Preprocessing (cleaning & lemmatization)

- Exploratory Data Analysis (EDA)

- NLP Sentiment Analysis using VADER

- Visualization & Insights

Data Collection using google-play-scrapper
"""

!pip install google-play-scraper

from google_play_scraper import Sort, reviews_all, reviews, app
import pandas as pd
import numpy as np

result = reviews_all(
    'com.zeptoconsumerapp',
    sleep_milliseconds=0,
    lang='en',
    country='in',
    count=1000,
    sort=Sort.NEWEST,

)

scrapeddata = pd.DataFrame(np.array(result),columns=['review'])

scrapeddata = scrapeddata.join(pd.DataFrame(scrapeddata.pop('review').tolist()))

scrapeddata.head(10)

len(scrapeddata.index)

scrapeddata=scrapeddata[['reviewId','content','score','at']]
scrapeddata.head(10)

scrapeddata.to_csv("zepto_review.csv", index = False)

# Commented out IPython magic to ensure Python compatibility.
#Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from textblob import Word
from wordcloud import WordCloud
!pip install vaderSentiment
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
plt.style.use('fivethirtyeight')
# %matplotlib inline

# Load dataset
reviews = pd.read_csv("zepto_review.csv", encoding='latin1')

# Dataset overview
print("Shape of dataset:", reviews.shape)
reviews.head()

# Check missing values
reviews.isna().sum()

#Cleaning Empty cells
reviews.dropna(inplace = True)

"""### Text Preprocessing
- Convert text to lowercase  
- Remove punctuation & numbers  
- Remove stopwords  
- Lemmatization  
"""

nltk.download('stopwords')
nltk.download('wordnet')
from nltk.corpus import stopwords

# Lowercasing
reviews['content'] = reviews['content'].str.lower()

# Remove punctuation & numbers
reviews['content'] = reviews['content'].str.replace('[^a-zA-Z]', ' ', regex=True)

# Remove stopwords
stop = stopwords.words('english')
reviews['content'] = reviews['content'].apply(lambda x: " ".join([word for word in x.split() if word not in stop]))

# Lemmatization
reviews['content'] = reviews['content'].apply(lambda x: " ".join([Word(word).lemmatize() for word in x.split()]))

reviews.head()

"""Exploratory Data Analysis"""

# Distribution of review scores
sns.countplot(data=reviews, x='score')
plt.title("Distribution of Review Scores")
plt.show()

# Review length distribution
reviews['review_length'] = reviews['content'].apply(len)
sns.histplot(reviews['review_length'], bins=30, kde=True)
plt.title("Distribution of Review Length")
plt.show()

# Most common words
from collections import Counter
words = " ".join(reviews['content']).split()
word_freq = Counter(words).most_common(20)
common_df = pd.DataFrame(word_freq, columns=['word', 'count'])

sns.barplot(x='count', y='word', data=common_df)
plt.title("Top 20 Most Frequent Words")
plt.show()

"""WordClouds"""

# Overall WordCloud
all_text = " ".join(reviews['content'])
wordcloud = WordCloud(background_color='white').generate(all_text)

plt.figure(figsize=(8,8))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.title("WordCloud of All Reviews")
plt.show()

positive = reviews[reviews['score'] >= 4]['content'].str.cat()
negative = reviews[reviews['score'] <= 2]['content'].str.cat()

wc_positive = WordCloud(background_color='white').generate(positive)
wc_negative = WordCloud(background_color='black').generate(negative)

fig, ax = plt.subplots(1,2, figsize=(15,7))
ax[0].imshow(wc_positive, interpolation='bilinear')
ax[0].axis("off")
ax[0].set_title("Positive Reviews")

ax[1].imshow(wc_negative, interpolation='bilinear')
ax[1].axis("off")
ax[1].set_title("Negative Reviews")
plt.show()

"""Sentiment Analysis with VADER"""

# Initialize VADER
analyzer = SentimentIntensityAnalyzer()

# Apply sentiment scoring
sentiments = reviews['content'].apply(lambda x: analyzer.polarity_scores(x))
sentiment_df = pd.DataFrame(sentiments.tolist())
reviews = pd.concat([reviews.reset_index(drop=True), sentiment_df], axis=1)

# Classify as Positive / Negative
reviews['Sentiment'] = np.where(reviews['compound'] >= 0, 'Positive', 'Negative')
reviews[['content', 'Sentiment']].head()

# Plot sentiment distribution
sns.countplot(data=reviews, x='Sentiment', hue='Sentiment', palette=['red','green'], legend=False)
plt.title("Overall Sentiment Distribution")
plt.show()

# Total, counts, and percentages
total = len(reviews)
counts = reviews['Sentiment'].value_counts().reindex(['Positive','Negative'], fill_value=0)
percentages = (counts / total * 100).round(2)

print(f"Total reviews: {total}")
print(f"Positive: {counts['Positive']} ({percentages['Positive']}%)")
print(f"Negative: {counts['Negative']} ({percentages['Negative']}%)")

"""Conclusion

84.28% - Positive Reviews

15.72% - Negative Reviews

Positive themes: fast delivery, convenience, discounts

Negative themes: app crashes, payment failures, cancellations

"""